---
layout: post
title: cgroup学习
category: linux
tags: cgroup
typora-root-url: ../

---

* content
{:toc}



# cgroup

## 子系统的功能

限制进程组可以使用的资源数量（Resource limiting ）。

- 比如：memory子系统可以为进程组设定一个memory使用上限，一旦进程组使用的内存达到限额再申请内存，就会出发OOM（out of memory）。

进程组的优先级控制（Prioritization ）。

- 比如：可以使用cpu子系统为某个进程组分配特定cpu share。

记录进程组使用的资源数量（Accounting ）。

- 比如：可以使用cpuacct子系统记录某个进程组使用的cpu时间。
    进程组隔离（Isolation）。比如：使用ns子系统可以使不同的进程组使用不同的namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间。

进程组控制（Control）。

- 比如：使用freezer子系统可以将进程组挂起和恢复。



典型的Cgroups子系统介绍
blkio – 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。
cpu – 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。
cpuacct – 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。
cpuset – 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。
devices – 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。
freezer – 这个子系统挂起或者恢复 cgroup 中的任务。
memory – 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成由那些任务使用的内存资源报告。
net_cls – 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。
ns – 名称空间子系统。

## 基本概念

|                           |                                                              |
| ------------------------- | ------------------------------------------------------------ |
| 任务（task）              | 在cgroups中，任务就是系统的一个进程                          |
| 控制族群（control group） | 控制族群就是一组按照某种标准划分的进程。 Cgroups中的资源控制都是以控制族群为单位实现。 一个进程组（process group）的进程可以使用cgroups以控制族群为单位分配的资源，同时受到cgroups以控制族群为单位设定的限制。 |
| 层级（hierarchy）         | 控制族群可以组织成hierarchical的形式，既一颗控制族群树。控制族群树上的子节点控制族群是父节点控制族群的孩子，继承父控制族群的特定的属性。 |
| 子系统（subsytem）        | 一个子系统就是一个资源控制器，比如cpu子系统就是控制cpu时间分配的一个控制器。子系统必须附加（attach）到一个层级上才能起作用，一个子系统附加到某个层级以后，这个层级上的所有控制族群都受到这个子系统的控制。 |


红色的是子系统

蓝色的是挂载点，黄色的是cgroup，共同构成层级hierarchy

![cgroups层级结构示意图](/assets/cgroup/cgroups层级结构示意图.png)

> 上图中的”M×N Linkage”说明的是css_set通过辅助数据结构可以与 cgroups 节点进行多对多的关联。但是 cgroups 的实现不允许css_set同时关联同一个cgroups层级结构下多个节点。 这是因为 cgroups 对同一种资源不允许有多个限制配置。
> 一个css_set关联多个 cgroups 层级结构的节点时，表明需要对当前css_set下的进程进行多种资源的控制。而一个 cgroups 节点关联多个css_set时，表明多个css_set下的进程列表受到同一份资源的相同限制。



## 原理

cgroup is largely composed of two parts - the core and controllers. cgroup core is primarily responsible for hierarchically organizing processes.  A cgroup controller is usually responsible for distributing a specific type of system resource along the hierarchy although there are utility controllers which serve purposes other than resource distribution.

cgroup主要由两部分组成&核心和控制器。cgroup core主要负责分层组织进程。cgroup控制器通常负责沿层次结构分发特定类型的系统资源，尽管有一些实用程序控制器用于除资源分配。

# 代码分析

![img](/assets/cgroup/cgroup代码架构图.png)

每个进程中，都对应有一个css_set结构体，css_set其实就是cgroup_subsys_state对象的集合，而每个cgroup_subsys_state代表一个subsystem。

struct cgroup_subsys_state *subsys[CGROUPSUBSYSCOUNT]：一个数组，每个元素指向一个cgroup_subsys_state，这个数组元素与subsystem的个数一一对应。

## 核心结构体

|                     |                                                              |
| ------------------- | ------------------------------------------------------------ |
| cgroup              |                                                              |
| cgroup_root         | cgroup层级的root                                             |
| cgroup_subsys_state | 每个subsystem子系统或者每个cgroup的状态信息                  |
| cgroup_subsys       | subsystem类型，各种回调函数                                  |
| cgrp_cset_link      | 一个task可以属于多个cgroup，一个cgroup也可以拥有多个task，这种M:N的关系，linux kernel中是通过cgrp_cset_link结构体表示的 |
| css_set             | 保存了所有cgroup_subsys_state指针，属于一个task，于是可以代表一个进程。 |
|                     |                                                              |
| link_css_set        | link_css_set函数的功能就是把一个css_set与一个cgroup通过struct cgrp_cset_link联系起来。cset_link是给struct cgroup查找struct cgrp_cset_link用的 |
| task_group          | cpu subsystem对应的子类                                      |
| blkcg               | io subsystem对应的子类                                       |
|                     |                                                              |



![这里写图片描述](/assets/2022-10-01-cgroup/SouthEast.png)

这张图也解释了linux代码中如何表现cgroup与subsystem之间多对多的关系。每个struct cgroup可以通过cgroup->cset_links和cgrp_cset_link->cset_link找到一串struct cgrp_cset_link，每个struct cgrp_cset_link都有着对应的css_set，这个css_set属于一个tast_struct（其实是多个），其中包含着subsystem。

于是通过遍历链表就能找到这个cgroup对应的所有task（其实找到的是css_set，但是对于Cgroups这个模块来说，关心的并不是task_struct，而是这个css_set）。

反之亦然，通过task_struct的cgroups变量（类型为struct css_set*）就能找到这个进程属于的所有cgroup。



struct task_group就是cpu subsystem对应的子类

```
/* task group related information */
struct task_group {
    struct cgroup_subsys_state css;
#ifdef CONFIG_FAIR_GROUP_SCHED
    /* schedulable entities of this group on each cpu */
    struct sched_entity **se;
    /* runqueue "owned" by this group on each cpu */
    struct cfs_rq **cfs_rq;
    unsigned long shares;

```

## 操作控制cgroup参数

groups通过VFS来和用户打交道, 用户通过将各个subsystem mount到某个目录下之后, cgroup文件系统会自动创建一系列虚拟文件, 用户通过向不同的文件读写数据控制Cgroups的行为.

具体对于CPU subsystem, 当向cpu.shares写入一个数字时, 内核执行的函数干的事情是修改这个cgroup对应的struct task_group中的shares变量. 这个函数是:cpu_shares_write_u64

```
static int cpu_shares_write_u64(struct cgroup_subsys_state *css,
                struct cftype *cftype, u64 shareval)
{
    if (shareval > scale_load_down(ULONG_MAX))
        shareval = MAX_SHARES;
    return sched_group_set_shares(css_tg(css), scale_load(shareval));
}
```

css_tg函数是找到具体的subsystem子类，

sched_group_set_shares遍历所有CPU，task_group管理的国有进程的sched_entity，然后update_cfs_shares



# 使用

## 普通控制参数

|                        |                                                              |
| ---------------------- | ------------------------------------------------------------ |
| cgroup.controller      | 该层级可以使用的所有controller，在root目录中列举了所有系统可以的controller，在子目录子cgrouop中的controller等于上级目录的subtree_control |
| cgroup.subtree_control | 列举了使能的controller，子cgroup中只能使用这些controller     |
|                        |                                                              |

```
为cgroup增加或者减少controller
echo '+cpu -memory' > /sys/fs/cgroup/cg1/cgroup.subtree_control
```

![img](/assets/2022-10-01-cgroup/FbtaxHierarchyExternal.png)

`hostcritical.slice` 系统核心功能必须保证

`workload.slice` 用户负载，次要保证，其中有用户的负载以及支持用户负载的服务

`system.slice` 系统的次要功能



为了消除子cgroup与父cgroup的内部进程竞争资源的情况，cgroup只有在不包含自己的进程时才能控制内存和IO分配给其子进程。即只有叶子节点才能包含进程



| File                     | Description                                     |
| ------------------------ | ----------------------------------------------- |
| `cgroup.events`          | `populated` 自身和后代cgroup是否包含可用的进程. |
| `cgroup.max.depth`       | cgroup的最大嵌套深度，最深还有多少cgroup层级.   |
| `cgroup.max.descendants` | cgroup最大包含多少后代cgroup                    |



## IO controller

当system使用过量IO的时候，不能够影响workload，system需要灵活的限制IO

cgroup2能够限制、测量、监控IO，包含每个cgroup的所有IO（buffered、metadata、swap、directIO）

| File          | Definition                                                   |
| ------------- | ------------------------------------------------------------ |
| `io.latency`  | Quality of service mechanism to guarantee a cgroup's level of IO completion latency. Specifies the number of milliseconds a process can wait before IO from other processes is given to it.  If the average completion latency is longer than the target set here, other processes are throttled to provide more IO, effectively prioritizing the job with the lowest `io.latency` setting.  `io.latency` is the currently preferred mechanism for IO control: See the [discussion of io.latency below](https://facebookmicrosites.github.io/cgroup2/docs/io-controller.html#protecting-workloads-with-iolatency) for more information. |
| `io.pressure` | Gives the percentage of wall time in which some or all tasks are waiting for a block device, or IO.  See the [PSI resource pressure metrics page](https://facebookmicrosites.github.io/cgroup2/docs/pressure-metrics.html) for more details. |
| `io.stat`     | IO usage statistics.  Lines are keyed by `$MAJ:$MIN` device numbers and not ordered. The following keys are defined:  `rbytes`: bytes read`wbytes`: bytes written`dbytes`: number of bytes discarded`rios`: number of read IOs`wios`: number of write IOs`dios`: number of discard (or trim) IOs.An example read output follows:  `8:16 rbytes=1459200 wbytes=314773504 rios=192 wios=353 dbytes=9973760 dios=79 8:0 rbytes=90430464 wbytes=299008000 rios=8950 wios=1252 dbytes=69632 dios=158` |
| `io.max`      | This is where you specify IO limits. Lines are keyed by `$MAJ:$MIN` device numbers and not ordered.  The following nested keys are defined.  `riops`: Max read IO operations per second`wiops`: Max write IO operations per second`rbps`: Max read bytes per second`wbps`: Max write bytes per second When writing, any number of nested key-value pairs can be specified in any order. You can specify `max` to remove a specific limit. If the same key is specified multiple times, the outcome is undefined.  BPS and IOPS are measured in each IO direction, and IOs are delayed if the limit is reached. Temporary bursts are allowed.  Setting read limit at 2M BPS and write at 120 IOPS for 8:16:  `echo "8:16 rbps=2097152 wiops=120" > io.max`  Reading returns the following:  `8:16 rbps=2097152 wbps=max riops=max wiops=120`  Write IOPS limit can be removed by writing the following:  `echo "8:16 wiops=max" > io.max`  Reading now returns the following:  `8:16 rbps=2097152 wbps=max riops=max wiops=max` |



## 代码

 

 grep -nr -A 5 'static struct cftype' block/

| static struct cftype |                                                 |
| -------------------- | ----------------------------------------------- |
| io.latency           | block/blk-iolatency.c                           |
| io.stat              | block/blk-cgroup.c                              |
| io.max               |                                                 |
| io.pressure          | kernel/cgroup/cgroup.c  cgroup_io_pressure_show |
| io.bfq.weight        |                                                 |
|                      |                                                 |

​				

# 参考

https://opensource.fb.com/linux



https://facebookmicrosites.github.io/resctl-demo-website/

https://github.com/facebookexperimental/resctl-demo



https://github.com/facebookincubator/oomd



